{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6af2ee81",
   "metadata": {},
   "source": [
    "---\n",
    "description: Monitosed\n",
    "output-file: tutorial.monitosed.html\n",
    "title: Monitosed\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825fea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from model import stagerNetAAE\n",
    "from utils import UnfreezeFcCrit\n",
    "\n",
    "# Set your paths\n",
    "github_path = 'fastAI/GitHub/' # path to GitHub Monitosed folder \n",
    "eeg_dir = '/home/JennebauffeC/pytorchVAE/fastAI/data/LEMON/Preprocessed/' # path to public dataset\n",
    "biowin_file_path = '/home/JennebauffeC/pytorchVAE/fastAI/Monitosed/Biowin/sub-001/VR_1_VRH.vhdr' # path to reference file for electrode positions\n",
    "data_dir = '/home/JennebauffeC/pytorchVAE/fastAI/data/LEMON'\n",
    "\n",
    "# device = torch.device(torch.cuda.current_device())\n",
    "dev = torch.device('cuda:1')\n",
    "device = torch.device(dev if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(device)\n",
    "print('the current device is: ', device)\n",
    "\n",
    "%cd fastAI/GitHub/\n",
    "from model20 import stagerNetAAE\n",
    "from utils1 import LossAttrMetric, GetLatentSpace, norm_batch, UnfreezeFcCrit, SwitchAttribute, distrib_regul_regression, hist_lab, plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_files = [file for file in eeg_dir.glob('*_HYP.mat')]\n",
    "rest_files = [file for file in eeg_dir.glob('*_Resting.mat')]\n",
    "vrh_files = [file for file in eeg_dir.glob('*_VRH.mat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1580c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hyp, y_hyp = preprocess_files(hyp_files, 1)\n",
    "x_resting, y_resting = preprocess_files(rest_files, 0)\n",
    "x_vrh, y_vrh = preprocess_files(vrh_files, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03049eb7",
   "metadata": {},
   "source": [
    "### Step 3: Create the Train/Valid sets for different combinations of EEG states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556462e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = create_epochs_from_tensors(data_path)\n",
    "x = torch.Tensor(get_ica(epochs), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475860eb",
   "metadata": {},
   "source": [
    "## Train the Auto-Encoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9fc799",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_filename = ''\n",
    "acc_factor = 1\n",
    "model = stagerNetAAE(latent_dim=64, channels=x.shape[1], timestamps=x.shape[-1], acc_factor=acc_factor, dropout_rate=.3)\n",
    "\n",
    "metrics = [rmse]\n",
    "learn = Learner(dls, model, loss_func = model.ae_loss_func, metrics=metrics, opt_func=ranger)\n",
    "learning_rate = learn.lr_find()\n",
    "print('learning rate: '+str(learning_rate.valley))\n",
    "learn.fit_flat_cos(n_epoch=100, lr=learning_rate.valley, \n",
    "                   cbs=[\n",
    "                        GradientAccumulation(n_acc=dls.bs*acc_factor),\n",
    "                        TrackerCallback(),\n",
    "                        SaveModelCallback(fname=ae_filename),\n",
    "                        EarlyStoppingCallback(min_delta=1e-4,patience=10)])\n",
    "\n",
    "state_dict = torch.load(f'models/{ae_filename}.pth') # load the best weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598b944",
   "metadata": {},
   "source": [
    "## Train Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f6f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_factor = 1\n",
    "model = stagerNetAAE(latent_dim=64, channels=x.shape[1], timestamps=x.shape[-1],\n",
    "                     acc_factor=acc_factor, dropout_rate=0.5,\n",
    "                     adv_weight=0.9, recons_weight=0.1)\n",
    "# pretrained_filename = 'monitosed_pretrained_LEMON_aae_10s_shared'\n",
    "# state_dict = torch.load(f'models/{pretrained_filename}.pth') # load the best weights\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model = model.to(device)\n",
    "model.gen_train = False\n",
    "\n",
    "# adv_filename = 'monitosed_BIOWIN_aae_REST_VRH_05_24_16h' #reference for adversarial\n",
    "adv_filename = 'monitosed_BIOWIN_aae_REST_VRH_05_24_17h_latent64'\n",
    "\n",
    "metrics = [LossAttrMetric(\"recons_loss\"),\n",
    "           LossAttrMetric(\"discrim_loss\"),\n",
    "           LossAttrMetric(\"adv_loss\")]\n",
    "learn = Learner(dls, model, loss_func=model.aae_loss_func_monitosed,\n",
    "               metrics=metrics, opt_func=ranger)\n",
    "\n",
    "learning_rate = learn.lr_find()\n",
    "print('learning rate: '+str(learning_rate.valley))\n",
    "learn.fit_flat_cos(n_epoch=100, lr=learning_rate.valley,\n",
    "# learn.fit_flat_cos(50, lr=1e-2,\n",
    "                        cbs=[\n",
    "                            GradientAccumulation(n_acc=dls.bs*acc_factor),\n",
    "                            TrackerCallback(monitor='adv_loss'),\n",
    "#                             CustomSaveModelCallback(fname=adv_filename, monitor='adv_loss', start_at=2),\n",
    "                            SaveModelCallback(fname=adv_filename, monitor='adv_loss'),\n",
    "                            EarlyStoppingCallback(min_delta=1e-4,patience=20,monitor='adv_loss'),\n",
    "                            UnfreezeFcCrit(switch_every=2)])\n",
    "\n",
    "state_dict = torch.load(f'models/{adv_filename}.pth') # load the best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = ''\n",
    "\n",
    "z, target = extract_latent(state_dict, save_path, save)\n",
    "plot_results(z.to(device),target.cpu(),filename=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a6db5",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb42b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_factor = 1\n",
    "model = stagerNetAAE(latent_dim=64, dropout_rate=.5, channels=x.shape[1],\n",
    "                     timestamps=x.shape[-1], acc_factor=acc_factor,\n",
    "                    recons_weight=.1, adv_weight=.4, classif_weight=.5)\n",
    "\n",
    "# pretrained_filename = 'monitosed_pretrained_LEMON_aae_10s_shared' # .pth of our best EC/EO model -> rename both\n",
    "# pretrained_filename = 'monitosed_BIOWIN_aae_classif_REST_VRH_05_24_17h_latent64' # .pth of our best model -> rename both\n",
    "# state_dict = torch.load(f'models/{pretrained_filename}.pth') # load the best weights\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model = model.to(device)\n",
    "\n",
    "classif_filename = ''\n",
    "\n",
    "metrics = [LossAttrMetric(\"recons_loss\"),\n",
    "           LossAttrMetric(\"adv_loss\"),\n",
    "           LossAttrMetric(\"discrim_loss\"),\n",
    "           LossAttrMetric(\"classif_loss\")]\n",
    "\n",
    "learn = Learner(dls, model, loss_func=model.aae_classif_loss_func_monitosed, metrics=metrics, opt_func=ranger, wd=1e-1)\n",
    "\n",
    "learn.fit_flat_cos(100, lr=1e-2,\n",
    "                        cbs=[\n",
    "                            GradientAccumulation(n_acc=dls.bs*acc_factor),\n",
    "                            TrackerCallback(monitor='valid_loss'),\n",
    "                            SaveModelCallback(fname=classif_filename, monitor='valid_loss'),\n",
    "                            EarlyStoppingCallback(min_delta=1e-4,patience=20,monitor='valid_loss'),\n",
    "                            UnfreezeFcCrit(switch_every=5)])\n",
    "\n",
    "state_dict = torch.load(f'models/{classif_filename}.pth') # load the best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d5787",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = ''\n",
    "\n",
    "z, target = extract_latent(state_dict, save_path, save)\n",
    "plot_results(z.to(device),target.cpu(),filename=save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
