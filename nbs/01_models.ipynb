{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models\n",
    "\n",
    "> All code related to our models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from fastai.data.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class stagerNetAAE(nn.Module):\n",
    "    def __init__(self, channels: int=23, timestamps: int=3001,\n",
    "                    acc_factor: int=8, dropout_rate: float=0.5, level: int=0,\n",
    "                    latent_dim: int=128, gan_depth: int=3, k_pool_size: int=13,\n",
    "                    recons_weight: float=0.1, adv_weight: float=0.5, classif_weight: float=0.4\n",
    "                ):\n",
    "        super(stagerNetAAE, self).__init__()\n",
    "        \n",
    "        self.channels = channels #number of input channels (spatial)\n",
    "        self.timestamps = timestamps #number of input timestamps (temporal)\n",
    "        self.acc_factor = acc_factor\n",
    "        self.latent_dim = latent_dim #embed_dim\n",
    "        self.k_pool_size = k_pool_size #embed_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.gan_depth = gan_depth\n",
    "        self.gen_train = True\n",
    "        self.level = level\n",
    "        self.global_loss = False\n",
    "        self.discrim_loss = 1.0\n",
    "        self.adv_loss = 1.0\n",
    "        self.recons_weight = recons_weight\n",
    "        self.adv_weight = adv_weight\n",
    "        self.classif_weight = classif_weight\n",
    "        \n",
    "        #=============Encoder=============#\n",
    "        self.conv1 = nn.Conv2d(1, self.channels, (1, self.channels), stride=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 16, (self.timestamps//60,1), stride=(1,1))\n",
    "        self.conv3 = nn.Conv2d(16, 16, (self.timestamps//60,1), stride=(1,1))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(self.k_pool_size,1), return_indices=True) \n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(16)\n",
    "        self.bn_lin = nn.BatchNorm1d(num_features=self.latent_dim)\n",
    "\n",
    "        self.fc_input_size = self._get_fc_input_size(self.timestamps)\n",
    "        self.fc_z = nn.Linear(self.fc_input_size, self.latent_dim)\n",
    "\n",
    "        #=============Decoder=============#\n",
    "        self.decoder_input = nn.Linear(self.latent_dim, self.fc_input_size)\n",
    "        self.unpool = nn.MaxUnpool2d(kernel_size = (self.k_pool_size,1))\n",
    "        self.deconv1 = nn.ConvTranspose2d(self.channels, 1, (1, self.channels), stride=(1, 1))\n",
    "        self.deconv2 = nn.ConvTranspose2d(16, 1, (self.timestamps//60,1), stride=(1,1))\n",
    "        self.deconv3 = nn.ConvTranspose2d(16, 16, (self.timestamps//60,1), stride=(1,1))\n",
    "\n",
    "        #===============GAN===============#\n",
    "        fcs = ['fc_crit0','fc_crit1','fc_crit2','fc_crit3','fc_crit4']\n",
    "        bns = ['bn_crit0','bn_crit1','bn_crit2','bn_crit3','bn_crit4']\n",
    "        for i in range(self.gan_depth-1):\n",
    "            self.add_module(fcs[i], nn.Linear(self.latent_dim//2**(i), self.latent_dim//2**(i+1)))\n",
    "            self.add_module(bns[i], nn.BatchNorm1d(num_features=self.latent_dim//2**(i+1)))\n",
    "        self.add_module(fcs[self.gan_depth-1], nn.Linear(self.latent_dim//2**(self.gan_depth-1), 1))\n",
    "        \n",
    "        #============Classifier============#\n",
    "        self.fc_clf_discr1 = nn.Linear(self.latent_dim, 2)\n",
    "            \n",
    "    def _get_fc_input_size(self, timestamps):\n",
    "        x = torch.randn(16, 1, timestamps, self.channels)\n",
    "        x,_,_,_,_ = self._forward_conv(x)\n",
    "        return x.shape[1]\n",
    "\n",
    "    def _forward_conv(self, inp):\n",
    "        inp = self.conv1(inp)\n",
    "        inp = inp.permute(0, 3, 2, 1)\n",
    "        inp = self.conv2(inp)\n",
    "        input_mp1 = inp.detach().clone()\n",
    "        inp, ind_maxpool1 = self.pool(inp)\n",
    "        inp = F.relu(inp)\n",
    "        inp = self.batchnorm1(inp)\n",
    "        inp = self.conv3(inp)\n",
    "        input_mp2 = inp.detach().clone()\n",
    "        inp, ind_maxpool2 = self.pool(inp)\n",
    "        inp = F.relu(inp)\n",
    "        result = self.batchnorm2(inp)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "        result = F.dropout(result, p=self.dropout_rate)\n",
    "        return result, ind_maxpool1, ind_maxpool2, input_mp1, input_mp2\n",
    "\n",
    "    def encode(self, inp: Tensor) -> List[Tensor]:\n",
    "        result, ind_maxpool1, ind_maxpool2, input_mp1, input_mp2 = self._forward_conv(inp)\n",
    "\n",
    "        z = self.fc_z(result)\n",
    "        zi = F.relu(self.bn_lin(z))\n",
    "\n",
    "        return [zi, ind_maxpool1, ind_maxpool2, input_mp1, input_mp2]\n",
    "    \n",
    "    def decode(self, z: Tensor, ind1, ind2, in1, in2) -> Tensor:\n",
    "        x = self.decoder_input(z)        \n",
    "        x = x.view(self.current_bs, 16, -1, self.channels) \n",
    "        x = self.unpool(x, indices=ind2, output_size = in2.size())\n",
    "        x = F.relu(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.deconv3(x)\n",
    "        x = self.unpool(x, indices=ind1, output_size = in1.size())\n",
    "        x = F.relu(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = x.permute(0, 3, 2, 1)\n",
    "        result = self.deconv1(x)        \n",
    "        return result\n",
    "\n",
    "    def latent_gan(self, zi: Tensor) -> Tensor:\n",
    "        x = zi.view(-1,self.latent_dim)\n",
    "        for i in range(self.gan_depth-1):\n",
    "            x = getattr(self,f'fc_crit{i}')(x)\n",
    "            x = F.leaky_relu(getattr(self,f'bn_crit{i}')(x),negative_slope=0.2)\n",
    "        x = getattr(self,f'fc_crit{self.gan_depth-1}')(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, inp: Tensor, **kwargs) -> Tensor:\n",
    "        if inp.dim() < 4:\n",
    "            inp = inp.unsqueeze(1)\n",
    "        self.ae_input = inp # needed to compute reconstruction loss\n",
    "\n",
    "        x = inp.permute(0, 1, 3, 2)\n",
    "        self.current_bs = x.shape[0]\n",
    "        zi, ind1, ind2, in1, in2 = self.encode(x)\n",
    "\n",
    "        self.zi = zi # needed to further display the latent space\n",
    "\n",
    "        zi_gan = zi.view(-1, self.latent_dim, 1)\n",
    "        self.gan_fake = self.latent_gan(zi_gan)\n",
    "        z = torch.randn_like(zi_gan)\n",
    "        z = F.dropout(z, p=self.dropout_rate)\n",
    "        self.gan_real = self.latent_gan(z)\n",
    "\n",
    "        decoded = self.decode(zi, ind1, ind2, in1, in2)\n",
    "        self.decoded = decoded\n",
    "        self.decoded = decoded.permute(0, 1, 3, 2)\n",
    "\n",
    "        self.pred_class = F.softmax(self.fc_clf_discr1(zi)).to(dev)\n",
    "  \n",
    "        pred_eeg = self.pred_class\n",
    "\n",
    "        return pred_eeg\n",
    "\n",
    "    def ae_loss_func(self, output, target):\n",
    "        delta = .5\n",
    "        huber = nn.HuberLoss(delta=delta)\n",
    "        recons_loss = (huber(self.decoded, self.ae_input) +\n",
    "                2*huber(self.decoded.std(dim=-1), self.ae_input.std(dim=-1)) # avoid the decoded signal to stay at 0\n",
    "                )\n",
    "        return recons_loss\n",
    "\n",
    "\n",
    "    def aae_loss_func_monitosed(self, output, target):\n",
    "        delta = .5\n",
    "        huber = nn.HuberLoss(delta=delta)\n",
    "        adversarial_loss = nn.BCELoss()\n",
    "\n",
    "        self.recons_loss = (huber(self.decoded, self.ae_input) +\n",
    "            2*huber(self.decoded.std(dim=-1), self.ae_input.std(dim=-1)) # avoid the decoded signal to stay at 0\n",
    "            )\n",
    "\n",
    "        if self.gen_train: #generator loss\n",
    "            # Measures generator's ability to fool the discriminator\n",
    "            discrim_tmp = torch.tensor(self.discrim_loss, requires_grad=False)\n",
    "            valid = torch.ones_like(self.gan_fake, requires_grad=False).detach()\n",
    "            self.adv_loss = adversarial_loss(self.gan_fake, valid) + discrim_tmp\n",
    "            loss = self.adv_weight * self.adv_loss + self.recons_weight * self.recons_loss # + 0.5 * self.classif_loss\n",
    "\n",
    "        else: #discriminator loss\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "            valid = 0.99*torch.ones_like(self.gan_real, requires_grad=False).detach()\n",
    "            valid = F.dropout(valid, p=self.dropout_rate)\n",
    "            fake = 0.01*torch.ones_like(self.gan_fake, requires_grad=False).detach()\n",
    "            fake = F.dropout(fake, p=self.dropout_rate)\n",
    "            self.real_loss = adversarial_loss(self.gan_real, valid)\n",
    "            self.fake_loss = adversarial_loss(self.gan_fake, fake)\n",
    "            self.discrim_loss = 0.6 * self.real_loss + 0.4 * self.fake_loss\n",
    "            loss = 10 * self.discrim_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def aae_classif_loss_func_monitosed(self, output, target):\n",
    "        delta = .5\n",
    "        huber = nn.HuberLoss(delta=delta)\n",
    "        adversarial_loss = nn.BCELoss()\n",
    "        bce = nn.CrossEntropyLoss()\n",
    "        rnd_weight = torch.empty(self.gan_fake.shape, requires_grad=False).uniform_(0.9, 1.0).to('cuda:0').detach()\n",
    "\n",
    "        self.classif_loss = bce(output, target)\n",
    "\n",
    "        self.recons_loss = (huber(self.decoded, self.ae_input) +\n",
    "            2*huber(self.decoded.std(dim=-1), self.ae_input.std(dim=-1)) # avoid the decoded signal to stay at 0\n",
    "            )\n",
    "\n",
    "        if self.gen_train: #generator loss\n",
    "            # Measures generator's ability to fool the discriminator\n",
    "            valid = rnd_weight * torch.ones_like(self.gan_fake, requires_grad=False).detach()\n",
    "            discrim_tmp = torch.tensor(self.discrim_loss, requires_grad=False)\n",
    "            self.adv_loss = (adversarial_loss(self.gan_fake.mean(0), valid.mean(0))\n",
    "                            + adversarial_loss(self.gan_fake.std(0), valid.std(0))\n",
    "                            + discrim_tmp)\n",
    "            loss = (self.adv_weight * self.adv_loss + self.recons_weight * self.recons_loss \n",
    "                    + self.classif_weight * self.classif_loss)\n",
    "\n",
    "        else: #discriminator loss\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "            valid = rnd_weight * torch.ones_like(self.gan_real, requires_grad=False).detach()\n",
    "            fake = (1-rnd_weight) * torch.ones_like(self.gan_fake, requires_grad=False).detach()\n",
    "            self.real_loss = (adversarial_loss(self.gan_real.mean(0), valid.mean(0))\n",
    "                            + adversarial_loss(self.gan_real.std(0), valid.std(0)))\n",
    "            self.fake_loss = (adversarial_loss(self.gan_fake.mean(0), fake.mean(0))\n",
    "                            + adversarial_loss(self.gan_fake.std(0), fake.std(0)))\n",
    "            self.discrim_loss = 0.6 * self.real_loss + 0.4 * self.fake_loss\n",
    "            loss = 10 * self.discrim_loss #the x10 factor avoid the discriminator loss to be responsible for early stopping\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### stagerNetAAE\n",
       "\n",
       ">      stagerNetAAE (channels:int=23, timestamps:int=3001, acc_factor:int=8,\n",
       ">                    dropout_rate:float=0.5, level:int=0, latent_dim:int=128,\n",
       ">                    gan_depth:int=3, k_pool_size:int=13,\n",
       ">                    recons_weight:float=0.1, adv_weight:float=0.5,\n",
       ">                    classif_weight:float=0.4)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### stagerNetAAE\n",
       "\n",
       ">      stagerNetAAE (channels:int=23, timestamps:int=3001, acc_factor:int=8,\n",
       ">                    dropout_rate:float=0.5, level:int=0, latent_dim:int=128,\n",
       ">                    gan_depth:int=3, k_pool_size:int=13,\n",
       ">                    recons_weight:float=0.1, adv_weight:float=0.5,\n",
       ">                    classif_weight:float=0.4)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(stagerNetAAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
