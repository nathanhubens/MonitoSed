{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> All code related to utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.tabular.all import *\n",
    "from tsai.all import *\n",
    "from torch import nn\n",
    "from fastai.vision.gan import *\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "from scipy.ndimage import convolve1d, gaussian_filter1d\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LossAttrMetric(Metric):\n",
    "    def __init__(self, attr):\n",
    "        self.attr_name = attr\n",
    "        self.vals = []\n",
    "    def reset(self):\n",
    "        self.vals = []\n",
    "    def accumulate(self, learn):\n",
    "        setattr(self, self.attr_name, getattr(learn, self.attr_name))\n",
    "        self.vals.append(getattr(self, self.attr_name))\n",
    "    @property\n",
    "    def value(self):\n",
    "        return torch.mean(torch.tensor(self.vals))\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.attr_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LossAttrMetric\n",
       "\n",
       ">      LossAttrMetric (attr)\n",
       "\n",
       "Blueprint for defining a metric"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LossAttrMetric\n",
       "\n",
       ">      LossAttrMetric (attr)\n",
       "\n",
       "Blueprint for defining a metric"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LossAttrMetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UnfreezeFcCrit(Callback):\n",
    "    def __init__(self, switch_every: int=7):\n",
    "        self.switch_every = switch_every  \n",
    "    # def before_batch(self):\n",
    "    def before_epoch(self):\n",
    "        self.learn.model.print_state = True\n",
    "        # print('Im in unfreeze')\n",
    "        # print(self.training, self.epoch)\n",
    "        if (self.epoch) % self.switch_every == 0:\n",
    "            print('train discriminator')\n",
    "            self.learn.model.gen_train = False\n",
    "            for name, param in self.learn.model.named_parameters():\n",
    "                if \"fc_crit\" in name:\n",
    "                    param.requires_grad_(True)\n",
    "                else:\n",
    "                    param.requires_grad_(False)\n",
    "        # elif self.training and (self.iter + 1) % (self.acc_factor * 4) == 0:\n",
    "        elif (self.epoch) % self.switch_every == 1:\n",
    "            print('train generator')\n",
    "            self.learn.model.gen_train = True\n",
    "            for name, param in self.learn.model.named_parameters():\n",
    "                if \"fc_crit\" in name:\n",
    "                    param.requires_grad_(False)\n",
    "                else:\n",
    "                    param.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### UnfreezeFcCrit\n",
       "\n",
       ">      UnfreezeFcCrit (switch_every:int=7)\n",
       "\n",
       "Basic class handling tweaks of the training loop by changing a `Learner` in various events"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### UnfreezeFcCrit\n",
       "\n",
       ">      UnfreezeFcCrit (switch_every:int=7)\n",
       "\n",
       "Basic class handling tweaks of the training loop by changing a `Learner` in various events"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(UnfreezeFcCrit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GetLatentSpace(Callback):\n",
    "    def __init__(self, cycle_len=None):\n",
    "        self.cycle_len_init = cycle_len\n",
    "    def before_validate(self):\n",
    "        self.cycle_len = ifnone(self.cycle_len_init,self.n_epoch)\n",
    "    def after_batch(self):\n",
    "        if not self.training:\n",
    "            if (self.epoch+1) % self.cycle_len == 0:\n",
    "                if not hasattr(self, 'zi_valid') or self.zi_valid.numel() == 0:\n",
    "                    if hasattr(self, 'zi'):\n",
    "                        self.learn.zi_valid = self.zi\n",
    "                    else:\n",
    "                        self.learn.zi_valid = self.generator.zi\n",
    "                else:\n",
    "                    if hasattr(self, 'zi'):\n",
    "                        self.learn.zi_valid = torch.vstack((self.learn.zi_valid,self.zi))\n",
    "                    else:\n",
    "                        self.learn.zi_valid = torch.vstack((self.learn.zi_valid,self.generator.zi))\n",
    "\n",
    "                # Generate labels tensor\n",
    "                new_labels = torch.tensor([-1.0 if item[0] == 0 else 1.0 for item in self.y], device=self.learn.zi_valid.device)\n",
    "                \n",
    "                # Concatenate labels tensor with existing labels tensor\n",
    "                self.learn.labels = torch.cat([self.labels, new_labels], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### GetLatentSpace\n",
       "\n",
       ">      GetLatentSpace (cycle_len=None)\n",
       "\n",
       "Basic class handling tweaks of the training loop by changing a `Learner` in various events"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### GetLatentSpace\n",
       "\n",
       ">      GetLatentSpace (cycle_len=None)\n",
       "\n",
       "Basic class handling tweaks of the training loop by changing a `Learner` in various events"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(GetLatentSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_lds_kernel_window(kernel, ks, sigma):\n",
    "    # Taken from https://github.com/YyzHarry/imbalanced-regression\n",
    "    assert kernel in ['gaussian', 'triang', 'laplace']\n",
    "    half_ks = (ks - 1) // 2\n",
    "    if kernel == 'gaussian':\n",
    "        base_kernel = [0.] * half_ks + [1.] + [0.] * half_ks\n",
    "        kernel_window = gaussian_filter1d(base_kernel, sigma=sigma) / max(gaussian_filter1d(base_kernel, sigma=sigma))\n",
    "    elif kernel == 'triang':\n",
    "        kernel_window = triang(ks)\n",
    "    else:\n",
    "        laplace = lambda x: np.exp(-abs(x) / sigma) / (2. * sigma)\n",
    "        kernel_window = list(map(laplace, np.arange(-half_ks, half_ks + 1))) / max(map(laplace, np.arange(-half_ks, half_ks + 1)))\n",
    "\n",
    "    return kernel_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_lds_kernel_window\n",
       "\n",
       ">      get_lds_kernel_window (kernel, ks, sigma)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_lds_kernel_window\n",
       "\n",
       ">      get_lds_kernel_window (kernel, ks, sigma)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_lds_kernel_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_normalized_scores(display=False):\n",
    "    # for desaturation area\n",
    "    area_db = []\n",
    "    with open(\"/home/JennebauffeC/pytorchVAE/label_area.txt\") as f :\n",
    "        ligne = f.readline().rstrip(\" \\n\")\n",
    "        while ligne:\n",
    "            ligne = list(map(int, ligne.split(\" \")))\n",
    "            patient = ligne[0]\n",
    "            area = ligne[1:]\n",
    "            area_db += area\n",
    "            ligne = f.readline().rstrip(\" \\n\")\n",
    "    print(len(area_db))\n",
    "\n",
    "    med_area = np.median(area_db)\n",
    "    norm_area = np.clip((area_db - med_area) / med_area, -1, 1)\n",
    "\n",
    "    print(med_area)\n",
    "    print(norm_area.min())\n",
    "    print(norm_area.max())\n",
    "\n",
    "    np.save('/home/JennebauffeC/pytorchVAE/norm_area_db.npy', norm_area)\n",
    "\n",
    "    # for apnea duration\n",
    "    duration_db = []\n",
    "    with open(\"/home/JennebauffeC/pytorchVAE/label_duree.txt\") as f :\n",
    "        ligne = f.readline().rstrip(\" \\n\")\n",
    "        while ligne:\n",
    "            ligne = list(map(float, ligne.split(\" \")))\n",
    "            patient = ligne[0]\n",
    "            duration = ligne[1:]\n",
    "            duration_db += duration\n",
    "            ligne = f.readline().rstrip(\" \\n\")\n",
    "    print(len(duration_db))\n",
    "\n",
    "    med_duration = np.median(duration_db)\n",
    "    norm_duration = np.clip((duration_db - med_duration) / med_duration, -1, 1)\n",
    "\n",
    "    print(med_duration)\n",
    "    print(norm_duration.min())\n",
    "    print(norm_duration.max())\n",
    "\n",
    "    np.save('/home/JennebauffeC/pytorchVAE/norm_duration_db.npy', norm_duration)\n",
    "\n",
    "    if display:\n",
    "        bins = np.arange(-1,1,.01) # fixed bin size\n",
    "        plt.hist(norm_duration, bins=bins)\n",
    "        plt.axvline(x = int(np.median(norm_duration)), color = 'r', label = f'median={str(int(np.median(norm_duration)))}')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_normalized_scores\n",
       "\n",
       ">      get_normalized_scores (display=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_normalized_scores\n",
       "\n",
       ">      get_normalized_scores (display=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_normalized_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the regularized linear regression of the latent space wrt the labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def distrib_regul_regression(z, target, nbins: int=100, get_reg: bool=False):\n",
    "    bin_edges = np.linspace(target.min(), target.max(), nbins+1)\n",
    "    # Assign each value in the data to its corresponding category based on the bin edges\n",
    "    labels = np.digitize(target, bin_edges)\n",
    "    bin_index_per_label = [int(label) for label in labels]\n",
    "\n",
    "    # calculate empirical (original) label distribution: [Nb,]\n",
    "    # \"Nb\" is the number of bins\n",
    "    Nb = max(bin_index_per_label) + 1\n",
    "    num_samples_of_bins = dict(Counter(bin_index_per_label))\n",
    "    emp_label_dist = [num_samples_of_bins.get(i, 0) for i in range(Nb)]\n",
    "\n",
    "    # lds_kernel_window: [ks,], here for example, we use gaussian, ks=5, sigma=2\n",
    "    lds_kernel_window = get_lds_kernel_window(kernel='gaussian', ks=5, sigma=2)\n",
    "    # calculate effective label distribution: [Nb,]\n",
    "    eff_label_dist = convolve1d(np.array(emp_label_dist), weights=lds_kernel_window, mode='constant')\n",
    "\n",
    "    # Use re-weighting based on effective label distribution, sample-wise weights: [Ns,]\n",
    "    eff_num_per_label = [eff_label_dist[bin_idx] for bin_idx in bin_index_per_label]\n",
    "    weights = [np.float32(1 / x) for x in eff_num_per_label]\n",
    "\n",
    "    reg = LinearRegression().fit(z, target.view(-1), sample_weight=weights)\n",
    "    out = np.dot(z, reg.coef_) + reg.intercept_\n",
    "\n",
    "    if get_reg:\n",
    "        return out, reg\n",
    "    else:\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### distrib_regul_regression\n",
       "\n",
       ">      distrib_regul_regression (z, target, nbins:int=100, get_reg:bool=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### distrib_regul_regression\n",
       "\n",
       ">      distrib_regul_regression (z, target, nbins:int=100, get_reg:bool=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(distrib_regul_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an histogram-like plot of the mean target value by x-bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def hist_lab(preds, target, nbins=42, reg=True):\n",
    "    data = np.vstack((preds, target.view(-1))).T\n",
    "\n",
    "    # séparer les colonnes de vos données\n",
    "    col1 = np.array([row[0] for row in data])\n",
    "    col2 = np.array([row[1] for row in data])\n",
    "\n",
    "    # calculer les bins\n",
    "    if reg:\n",
    "        bins = np.percentile(col1, np.linspace(0, 100, nbins))\n",
    "    else:\n",
    "        bins = np.linspace(min(col1), max(col1), nbins)\n",
    "\n",
    "    # calculer les moyennes pour chaque bin\n",
    "    bin_means = [np.mean(col2[(col1 >= bins[i]) & (col1 < bins[i+1])]) for i in range(len(bins)-1)]\n",
    "    # normalize in [-1,1]\n",
    "    bin_means = (bin_means - min(bin_means))/(max(bin_means)-min(bin_means)) * 2 - 1\n",
    "\n",
    "    # tracer le barplot (avec bins regularisées)\n",
    "    bins = np.linspace(min(col1), max(col1), nbins)\n",
    "    plt.bar(bins[:-1], bin_means, width=bins[1]-bins[0], color='#1f77b4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### hist_lab\n",
       "\n",
       ">      hist_lab (preds, target, nbins=42, reg=True)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### hist_lab\n",
       "\n",
       ">      hist_lab (preds, target, nbins=42, reg=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(hist_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_results(z,lab_gather,filename,nbins=24):\n",
    "    sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "    y_pred = distrib_regul_regression(z.cpu().detach().numpy(), lab_gather)\n",
    "    accuracy = accuracy_score(lab_gather>0, y_pred>0)\n",
    "    f1 = f1_score(lab_gather>0, y_pred>0)\n",
    "    roc_auc = roc_auc_score(lab_gather>0, y_pred>0)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"ROC-AUC Score:\", roc_auc)\n",
    "\n",
    "    # Compute the mean error and compare to the mean error of randomly sorted trials\n",
    "    y_sort, idx_sort = torch.Tensor(y_pred).sort()\n",
    "    idx_rnd = np.random.permutation(np.arange(0,len(idx_sort)))\n",
    "    lab_sort = lab_gather[idx_sort]\n",
    "    lab_rnd = lab_gather[idx_rnd]\n",
    "\n",
    "    # Plot useful figures\n",
    "    diverging_norm = mcolors.TwoSlopeNorm(vmin=lab_gather.min(),vcenter=0.0,vmax=lab_gather.max())\n",
    "    mapper = plt.cm.ScalarMappable(norm=diverging_norm, cmap='YlOrBr_r')\n",
    "    colors = mapper.to_rgba(lab_gather)\n",
    "\n",
    "    plt.figure()\n",
    "    nbins = nbins\n",
    "    hist_lab(y_pred, lab_gather, nbins)\n",
    "    plt.xlabel(\"Latent Severity Scale\")\n",
    "    plt.ylabel(\"Mean Hand-made Score S_h\")\n",
    "    plt.xticks(ticks=[y_pred.min(),y_pred.max()], labels=[0,1])\n",
    "    plt.savefig(\"results/z_\"+str(filename)+\"_regression_hist\")\n",
    "\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x=y_pred, y=np.random.uniform(-50000, 50000,len(y_pred)), c=colors)\n",
    "    plt.title(\"1-D distribution of the sorted predictions\")\n",
    "    plt.xticks(ticks=[y_pred.min(),y_pred.max()], labels=[0,1])\n",
    "    plt.savefig(\"results/z_\"+str(filename)+\"_1D\")\n",
    "\n",
    "    tsne = TSNE(random_state=42)\n",
    "    predictions_embedded = tsne.fit_transform(z.cpu().detach().numpy())\n",
    "\n",
    "    #Compute linear regression from 2D space\n",
    "    y_pred_embed = distrib_regul_regression(predictions_embedded, lab_gather)\n",
    "\n",
    "    accuracy = accuracy_score(lab_gather>0, y_pred_embed>0)\n",
    "    f1 = f1_score(lab_gather>0, y_pred_embed>0)\n",
    "    roc_auc = roc_auc_score(lab_gather>0, y_pred_embed>0)\n",
    "\n",
    "    print(\"Accuracy 2D:\", accuracy)\n",
    "    print(\"F1 Score 2D:\", f1)\n",
    "    print(\"ROC-AUC Score 2D:\", roc_auc)\n",
    "\n",
    "    # Calculate the mean of x and y for the darkest and lightest colors\n",
    "    q1, q3 = np.percentile(y_pred_embed, [25, 75])\n",
    "    dark_mask = y_pred_embed <= q1\n",
    "    light_mask = y_pred_embed >= q3\n",
    "    dark_mean = np.mean(predictions_embedded[dark_mask, :], axis=0)\n",
    "    light_mean = np.mean(predictions_embedded[light_mask, :], axis=0)\n",
    "    # Get the difference between dark_mean and light_mean\n",
    "    diff = light_mean - dark_mean\n",
    "    # Calculate the slope\n",
    "    m = diff[1] / diff[0]\n",
    "    # Calculate the intercept\n",
    "    b = dark_mean[1] - m * dark_mean[0]\n",
    "\n",
    "    # Calculer les points de début et de fin de la droite régressée\n",
    "    x, y = predictions_embedded[:, 0], predictions_embedded[:, 1]\n",
    "    max_x = np.max(np.abs(x)) - 5\n",
    "    max_y = np.max(np.abs(y)) - 5\n",
    "    if max_x >= max_y:\n",
    "        x_min, x_max = -max_x, max_x\n",
    "    else:\n",
    "        x_min, x_max = -np.abs((-max_y - b) / m), np.abs((max_y - b) / m)\n",
    "    y_min, y_max = x_min * m + b, x_max * m + b\n",
    "    # Define start/end point of the arrow\n",
    "    start = (x_min,y_min)\n",
    "    end = (x_max,y_max)\n",
    "\n",
    "    # Sort the trials along the severity direction \n",
    "    x_proj = []\n",
    "    for x, y in predictions_embedded:\n",
    "        x_proj.append((x + m * y - m * b) / (1 + m ** 2))\n",
    "    x_proj = np.array(x_proj)\n",
    "\n",
    "    if dark_mean[0] < light_mean[0]:\n",
    "        _, idx_sort = torch.tensor(x_proj).sort()\n",
    "    elif dark_mean[0] > light_mean[0]:\n",
    "        _, idx_sort = torch.tensor(-x_proj).sort()\n",
    "    else:\n",
    "        raise ValueError(\"Severity direction is vertical\")\n",
    "\n",
    "    diverging_norm = mcolors.TwoSlopeNorm(vmin=lab_gather.min(),vcenter=0.0,vmax=lab_gather.max())\n",
    "    mapper = plt.cm.ScalarMappable(norm=diverging_norm, cmap='YlOrBr_r')\n",
    "    colors = mapper.to_rgba(lab_gather)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.scatterplot(x=predictions_embedded[:,0], y=predictions_embedded[:,1], hue=lab_gather, palette='deep')\n",
    "    # Plot the line along the first principal component\n",
    "    ax.arrow(start[0], start[1], end[0]-start[0], end[1]-start[1], linewidth=3,\n",
    "              head_width=10, head_length=10, fc='r', ec='r', length_includes_head=True)\n",
    "    # Define x,y limits\n",
    "    maxabs = np.max(np.abs(predictions_embedded)) + 5\n",
    "    plt.xlim([-maxabs, maxabs])\n",
    "    plt.ylim([-maxabs, maxabs])\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    custom_labels = {\"-1.0\": \"Rest\", \"1.0\": \"VRH\"}\n",
    "    labels = [custom_labels[label] for label in labels]\n",
    "    plt.legend(handles, labels)\n",
    "\n",
    "    plt.title(\"Z representations in 2D using TSNE\")\n",
    "    plt.savefig(\"results/z_\"+str(filename)+\"_tsne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### plot_results\n",
       "\n",
       ">      plot_results (z, lab_gather, filename, nbins=24)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### plot_results\n",
       "\n",
       ">      plot_results (z, lab_gather, filename, nbins=24)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(plot_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
