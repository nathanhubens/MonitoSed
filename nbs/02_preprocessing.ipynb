{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing\n",
    "\n",
    "> All code related to preprocessing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mne'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmne\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzarr\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmne\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ICA\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mne'"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import torch\n",
    "import mne\n",
    "import zarr\n",
    "from mne.preprocessing import ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_data(data_path, save=False):\n",
    "    # Load MATLAB EEG structure\n",
    "    matlab_data = scipy.io.loadmat(data_path+'/preprocessed_eeg.mat')  # Update 'your_file.mat' with your MATLAB file name\n",
    "\n",
    "    # Extract relevant information\n",
    "    fsample = float(matlab_data['preprocessed_eeg']['fsample'][0][0][0][0])  # Sampling frequency\n",
    "    trial = matlab_data['preprocessed_eeg']['trial'][0][0]  # Trial data\n",
    "    label = [re.findall(r\"\\['(.*?)'\\]\", str(l[0]))[0] for l in matlab_data['preprocessed_eeg']['label'][0][0]]  # Electrode labels\n",
    "\n",
    "    # Create an MNE Info object\n",
    "    info = mne.create_info(ch_names=label, sfreq=fsample, ch_types='eeg')\n",
    "\n",
    "    # Create an MNE Raw object\n",
    "    data_trial = np.stack(trial[0], axis=0)\n",
    "    _, n_channels, _ = data_trial.shape\n",
    "    data_trial_reshaped = data_trial.transpose(1, 0, 2).reshape(n_channels, -1)\n",
    "    raw = mne.io.RawArray(data_trial_reshaped, info)\n",
    "    events = [[i,0,1] for i in range(data_trial.shape[0])]\n",
    "    epochs = mne.Epochs(raw, events, tmin=0, tmax=10, baseline=(0, 0))\n",
    "\n",
    "    if save: raw.save('output_raw.fif', overwrite=True)\n",
    "\n",
    "    return raw, events, epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### load_data\n",
       "\n",
       ">      load_data (data_path, save=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### load_data\n",
       "\n",
       ">      load_data (data_path, save=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def EEG_preprocess(raw, label, get_raw=False):\n",
    "\n",
    "    # Define the new sampling frequency and low-pass cutoff frequency\n",
    "    new_sfreq = 50.0  # Hz\n",
    "    lowpass_freq = 24.0  # Hz\n",
    " \n",
    "    # Apply a low-pass filter to the data\n",
    "    raw_filtered = raw.copy().filter(l_freq=None, h_freq=lowpass_freq)\n",
    " \n",
    "    # Resample the data\n",
    "    raw_filtered = raw_filtered.copy().resample(sfreq=new_sfreq)\n",
    " \n",
    "    # Fit EEG cap montage to Biowin data (127 electrodes)\n",
    "    monitosed_VR1 = mne.io.read_raw_brainvision(biowin_file_path, preload=True)\n",
    "    montage = monitosed_VR1.get_montage()\n",
    "    electrode_info = montage.get_positions()['ch_pos']\n",
    "    locs128 = np.array(list(electrode_info.values()))\n",
    "    names128 = list(electrode_info.keys())\n",
    "    print(len(names128))\n",
    "\n",
    "    channels_to_remove = [item for item in label if item not in names128]\n",
    "    raw_filtered.drop_channels(channels_to_remove)\n",
    "    my_chan = raw_filtered.info['ch_names']\n",
    "    electrode_info = {ch_name: montage.get_positions()['ch_pos'][ch_name] for ch_name in my_chan}\n",
    "    locs64 = np.array(list(electrode_info.values())) \n",
    "    names64 = list(electrode_info.keys())\n",
    "    missing_channels = [channel for channel in names128 if channel not in my_chan]\n",
    "\n",
    "    if len(missing_channels)>0:\n",
    "\n",
    "        # create an array of zeros to simulate the missing channels\n",
    "        zeros_array = np.zeros((len(missing_channels), raw_filtered.n_times))\n",
    " \n",
    "        # create a new RawArray object for the missing channels\n",
    "        missing_info = mne.create_info(ch_names=missing_channels,\n",
    "                                       sfreq=raw_filtered.info['sfreq'],\n",
    "                                       ch_types='eeg')\n",
    "\n",
    "        raw_missing = mne.io.RawArray(zeros_array, missing_info)\n",
    "        raw_missing = raw_missing.filter(l_freq=None, h_freq=raw_filtered.info[\"lowpass\"])\n",
    " \n",
    "        # interpolate the missing channels\n",
    "        raw_interpolated = raw_filtered.copy().add_channels([raw_missing])\n",
    "        raw_interpolated = raw_interpolated.reorder_channels(names128)\n",
    " \n",
    "        # Set the montage on the Raw object\n",
    "        raw_interpolated.set_montage(montage)\n",
    " \n",
    "        # Define bad channels \n",
    "        raw_interpolated.info['bads'] = missing_channels\n",
    "        \n",
    "        # Interpolate the missing channels\n",
    "        raw_interpolated.interpolate_bads(reset_bads=True)\n",
    "\n",
    "    else:\n",
    "        raw_interpolated = raw_filtered.copy()\n",
    "    print('interpolated: ', raw_interpolated)\n",
    " \n",
    "    if get_raw:\n",
    "        return raw_interpolated\n",
    " \n",
    "    # Get the data from the epochs object\n",
    "    data = raw_interpolated.get_data()\n",
    "    # Convert to a torch tensor\n",
    "    data_tensor = torch.tensor(data)\n",
    "    # Print the shape of the data tensor\n",
    "    print('data tensor shape: ', data_tensor.shape)\n",
    "    return data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### EEG_preprocess\n",
       "\n",
       ">      EEG_preprocess (raw, label, get_raw=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### EEG_preprocess\n",
       "\n",
       ">      EEG_preprocess (raw, label, get_raw=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(EEG_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def EEG_preprocess_eoec(raw, EC=True, get_raw=False):\n",
    "    # Define epoch duration and overlap\n",
    "    epoch_duration = 10  # in seconds\n",
    "    overlap = 0  # in seconds\n",
    "\n",
    "    # Define the new sampling frequency and low-pass cutoff frequency\n",
    "    new_sfreq = 50.0  # Hz\n",
    "    lowpass_freq = 24.0  # Hz\n",
    "\n",
    "    # Apply a low-pass filter to the data\n",
    "    raw_filtered = raw.copy().filter(l_freq=None, h_freq=lowpass_freq)\n",
    "\n",
    "    # Resample the data\n",
    "    raw_filtered = raw_filtered.copy().resample(sfreq=new_sfreq)\n",
    "\n",
    "    # Fit EEG cap montage to Biowin data (127 electrodes)\n",
    "    montage = mne.channels.make_standard_montage('biosemi128')\n",
    "    file_path = '/home/JennebauffeC/pytorchVAE/fastAI/Monitosed/Biowin/sub-001/VR_1_VRH.vhdr'\n",
    "    monitosed_VR1 = mne.io.read_raw_brainvision(file_path, preload=True)\n",
    "    montage = monitosed_VR1.get_montage()\n",
    "    electrode_info = montage.get_positions()['ch_pos']\n",
    "    names128 = list(electrode_info.keys())\n",
    "    \n",
    "    mapping_dict = {}\n",
    "    if 'PO9' in raw_filtered.info['ch_names']:\n",
    "        mapping_dict['PO9'] = 'P9'\n",
    "    if 'PO10' in raw_filtered.info['ch_names']:\n",
    "        mapping_dict['PO10'] = 'P10'\n",
    "    raw_filtered.rename_channels(mapping_dict)\n",
    "\n",
    "    electrode_info = raw_filtered.get_montage().get_positions()['ch_pos']\n",
    "    names64 = list(electrode_info.keys())\n",
    "        \n",
    "    channels_to_remove = [item for item in names64 if item not in names128]\n",
    "    raw_filtered.drop_channels(channels_to_remove)\n",
    "\n",
    "    # Get the list of all channel names\n",
    "    my_chan = raw_filtered.info['ch_names']\n",
    "\n",
    "    missing_channels = [channel for channel in names128 if channel not in my_chan]\n",
    "\n",
    "    # create an array of zeros to simulate the missing channels\n",
    "    zeros_array = np.zeros((len(missing_channels), raw_filtered.n_times))\n",
    "\n",
    "    # create a new RawArray object for the missing channels\n",
    "    missing_info = mne.create_info(ch_names=missing_channels, sfreq=raw_filtered.info['sfreq'], ch_types='eeg')\n",
    "    raw_missing = mne.io.RawArray(zeros_array, missing_info)\n",
    "    raw_missing = raw_missing.filter(l_freq=None, h_freq=raw_filtered.info[\"lowpass\"])\n",
    "    \n",
    "    # interpolate the missing channels\n",
    "    raw_interpolated = raw_filtered.copy().add_channels([raw_missing])\n",
    "    raw_interpolated = raw_interpolated.reorder_channels(names128)\n",
    "    \n",
    "    # Set the montage on the Raw object\n",
    "    raw_interpolated.set_montage(montage)\n",
    "\n",
    "    # Define bad channels \n",
    "    raw_interpolated.info['bads'] = missing_channels\n",
    "\n",
    "    # Interpolate the missing channels\n",
    "    raw_interpolated.interpolate_bads(reset_bads=True)\n",
    "\n",
    "    if get_raw:\n",
    "        return raw_interpolated\n",
    "\n",
    "    # Convert annotations to events\n",
    "    events, _ = mne.events_from_annotations(raw_interpolated)\n",
    "\n",
    "    # Keep only the events corresponding to the majority value\n",
    "    event_index = np.bincount(events[:, -1]).argmax()\n",
    "    events = mne.pick_events(events, include=[event_index])\n",
    "\n",
    "    # Extract epochs\n",
    "    epochs = mne.Epochs(raw_interpolated, events, tmin=0, tmax=epoch_duration,\n",
    "                        baseline=None, preload=True, event_repeated='merge')\n",
    "\n",
    "    # Get the start times of the first epoch\n",
    "    start_times = epochs.events[:, 0] / raw_interpolated.info['sfreq']\n",
    "\n",
    "    # Define the end times of each epoch\n",
    "    end_times = start_times[1:]\n",
    "    \n",
    "    # Iterate over the epochs and merge those that overlap\n",
    "    merged_epochs = []\n",
    "    i = 0\n",
    "    while i < len(start_times)-2:\n",
    "        start = start_times[i]\n",
    "        end = end_times[i]\n",
    "        j = i + 1\n",
    "        while j < len(end_times) and start_times[j] - overlap <= end and end_times[j] - start <= epoch_duration:\n",
    "            end = max(end, end_times[j])\n",
    "            j += 1\n",
    "        merged_epochs.append((start, end))\n",
    "        i = j\n",
    "\n",
    "    # Create a new list of events based on the merged epochs\n",
    "    merged_events = []\n",
    "    for start, end in merged_epochs:\n",
    "        index = np.argmin(np.abs(events[:, 0] / raw_interpolated.info['sfreq'] - start))\n",
    "        merged_events.append((int(events[index, 0]), 0, events[index, 2]))\n",
    "\n",
    "    # Create a new Epochs object from the merged events\n",
    "    merged_epochs = mne.Epochs(raw_interpolated, merged_events, tmin=0, tmax=epoch_duration,\n",
    "                               baseline=None, preload=True)\n",
    "\n",
    "    # Get the data from the epochs object\n",
    "    data = merged_epochs.get_data()\n",
    "\n",
    "    # Transpose the data array to have the channels dimension first\n",
    "    data = np.transpose(data, (0, 1, 2))\n",
    "\n",
    "    # Convert the numpy array to a torch tensor\n",
    "    data_tensor = torch.from_numpy(data)\n",
    "    \n",
    "    # Set the corresponding label (EC vs EO)\n",
    "    if EC:\n",
    "        label = [0 for _ in range(data_tensor.shape[0])]\n",
    "    else:\n",
    "        label = [1 for _ in range(data_tensor.shape[0])]\n",
    "    # Print the shape of the data tensor\n",
    "    print('data tensor shape: ', data_tensor.shape)\n",
    "    print('labels length: ', len(label))\n",
    "\n",
    "    return data_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### EEG_preprocess_eoec\n",
       "\n",
       ">      EEG_preprocess_eoec (raw, EC=True, get_raw=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### EEG_preprocess_eoec\n",
       "\n",
       ">      EEG_preprocess_eoec (raw, EC=True, get_raw=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(EEG_preprocess_eoec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous prenons un sujet comme référence pour la construction de notre DB: \n",
    "\n",
    "Exemple: \n",
    "\n",
    " > file_path = '/home/JennebauffeC/pytorchVAE/fastAI/Monitosed/Biowin/sub-001/VR_1_VRH.vhdr': "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_preprocessed_EEG(files):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for f in files:\n",
    "        tmp_x, tmp_y = EEG_preprocess(f)\n",
    "        x.append(tmp_x)\n",
    "        y.extend(tmp_y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_preprocessed_EEG\n",
       "\n",
       ">      get_preprocessed_EEG (files)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_preprocessed_EEG\n",
       "\n",
       ">      get_preprocessed_EEG (files)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_preprocessed_EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def preprocess_files(file_paths, label_value):\n",
    "    x_temp = []\n",
    "    y_temp = []\n",
    "    for file_path in tqdm(file_paths):\n",
    "        # Load MATLAB EEG structure\n",
    "        matlab_data = scipy.io.loadmat(file_path)\n",
    "        \n",
    "        # Extract relevant information\n",
    "        fsample = float(matlab_data['preprocessed_eeg']['fsample'][0][0][0][0])\n",
    "        trial = matlab_data['preprocessed_eeg']['trial'][0][0]  # Trial data\n",
    "        label = [re.findall(r\"\\['(.*?)'\\]\", str(l[0]))[0] for l in matlab_data['preprocessed_eeg']['label'][0][0]]  # Electrode labels\n",
    "        \n",
    "        # Create an MNE Info object\n",
    "        info = mne.create_info(ch_names=label, sfreq=fsample, ch_types='eeg')\n",
    "        \n",
    "        for item in tqdm(trial[0]):\n",
    "            raw = mne.io.RawArray(item, info)\n",
    "            processed_data = EEG_preprocess(raw, label)  # Assuming this function returns the preprocessed data\n",
    "            print(processed_data.shape)\n",
    "            break\n",
    "            x_temp.append(processed_data)\n",
    "            y_temp.append(label_value)\n",
    "    \n",
    "    return x_temp, y_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### preprocess_files\n",
       "\n",
       ">      preprocess_files (file_paths, label_value)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### preprocess_files\n",
       "\n",
       ">      preprocess_files (file_paths, label_value)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(preprocess_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please respect the BIDS format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def preprocess_files_eoec(eeg_dir):\n",
    "    # Properly read the data\n",
    "    # Get a list of all subdirectories\n",
    "    subdirs = next(os.walk(eeg_dir))[1]\n",
    "    # Get only the final folder names\n",
    "    sub_list = [os.path.basename(os.path.normpath(subdir)) for subdir in subdirs if 'sub' in subdir]\n",
    "\n",
    "    # Loop across all subjects\n",
    "    x = []\n",
    "    y = []\n",
    "    for i,sub_id in enumerate(sub_list):\n",
    "        clear_output(wait=True)\n",
    "        print('subject ', i)\n",
    "        filename = f'{sub_id}/{sub_id}_EC.set'\n",
    "        filepath = os.path.join(eeg_dir, filename)\n",
    "        tmp_x, tmp_y = EEG_preprocess(filepath, EC=True)\n",
    "        x.append(tmp_x)\n",
    "        y.extend(tmp_y)\n",
    "        print('eye closed done')\n",
    "        filename = f'{sub_id}/{sub_id}_EO.set'\n",
    "        filepath = os.path.join(eeg_dir, filename)\n",
    "        tmp_x, tmp_y = EEG_preprocess(filepath, EC=False)\n",
    "        x.append(tmp_x)\n",
    "        y.extend(tmp_y)\n",
    "\n",
    "    # Convert input list to tensor\n",
    "    x = torch.vstack(x)\n",
    "    y_tensor = torch.tensor([[0, 1] if lab == 0 else [1, 0] for lab in y])\n",
    "\n",
    "    return x, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### preprocess_files_eoec\n",
       "\n",
       ">      preprocess_files_eoec (eeg_dir)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### preprocess_files_eoec\n",
       "\n",
       ">      preprocess_files_eoec (eeg_dir)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(preprocess_files_eoec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_binary_combinations(x1, x2, y1, y2, save_path_x, save_path_y):\n",
    "\n",
    "    split_index_hyp = int(len(x1) * 0.75)\n",
    "    split_index_resting = int(len(x2) * 0.75)\n",
    "\n",
    "    x_train = x1[:split_index_hyp] + x2[:split_index_resting]\n",
    "    x_val = x1[split_index_hyp:] + x2[split_index_resting:]\n",
    "\n",
    "    y_train = y1[:split_index_hyp] + y2[:split_index_resting]\n",
    "    y_val = y1[split_index_hyp:] + y2[split_index_resting:]\n",
    "\n",
    "    x_final = x_train + x_val\n",
    "    y_final = y_train + y_val\n",
    "\n",
    "    x_final = torch.stack(x_final); x_final.shape\n",
    "        \n",
    "    # Save the input as Zarr file to save disk space and ease data loading\n",
    "    zarr.save(save_path_x, x_final.numpy())\n",
    "    # Save the labels\n",
    "    torch.save(y_final, save_path_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### create_binary_combinations\n",
       "\n",
       ">      create_binary_combinations (x1, x2, y1, y2, save_path_x, save_path_y)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### create_binary_combinations\n",
       "\n",
       ">      create_binary_combinations (x1, x2, y1, y2, save_path_x, save_path_y)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(create_binary_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_epochs_from_tensors(data_path):\n",
    "    # Load the Zarr file\n",
    "    x_zarr = zarr.open(f'{data_path}/x.zarr', mode='r')\n",
    "\n",
    "    # Define channel names (replace with your actual channel names)\n",
    "    ch_names = [f'Channel_{i}' for i in range(127)]\n",
    "\n",
    "    # Define channel types (replace with your actual channel types)\n",
    "    ch_types = ['eeg'] * 127\n",
    "\n",
    "    # Create an info object\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=50, ch_types=ch_types)\n",
    "\n",
    "    # Create EpochsArray\n",
    "    epochs = mne.EpochsArray(x_zarr, info)\n",
    "\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### create_epochs_from_tensors\n",
       "\n",
       ">      create_epochs_from_tensors (data_path)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### create_epochs_from_tensors\n",
       "\n",
       ">      create_epochs_from_tensors (data_path)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(create_epochs_from_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_ica(epochs, save_path, save=False):\n",
    "    # Compute ICA components\n",
    "    filt_raw = epochs.copy().filter(l_freq=1.0, h_freq=24)\n",
    "    ica = ICA(n_components=42, max_iter=\"auto\", random_state=97)\n",
    "    ica.fit(filt_raw)\n",
    "    ica_sources = ica.get_sources(filt_raw).get_data()\n",
    "    if save: zarr.save(ica_sources, save_path)\n",
    "    return ica_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_ica\n",
       "\n",
       ">      get_ica (epochs, save_path, save=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_ica\n",
       "\n",
       ">      get_ica (epochs, save_path, save=False)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
